{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61376dc9",
   "metadata": {},
   "source": [
    "# COMP 551 — Assignment 4\n",
    "\n",
    "Authors:\n",
    " - Bernier, Audréanne\n",
    " - Coull-Neveu, Ben\n",
    " - Trachsel-Bourbeau, Anjara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e00c5",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52a833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import pickle # to save models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5f7e9",
   "metadata": {},
   "source": [
    "Plot defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf40374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['legend.fontsize'] = 'medium'\n",
    "plt.rcParams['legend.fancybox'] = False\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['grid.linewidth'] = 0.5\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "plt.rcParams['axes.autolimit_mode'] = 'data'  # default, ensures autoscale uses data\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "\n",
    "# set default save directory and parameters\n",
    "SAVEDIR = './figures/'\n",
    "MODELDIR = './models/'\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "os.makedirs(MODELDIR, exist_ok=True)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182ceb1",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "X is input data that include text sequences\n",
    "\n",
    "Y is target value \n",
    "\n",
    "YL1 is target value of level one (parent label) --> scientific field {0-6}\n",
    "\n",
    "YL2 is target value of level one (child label) --> subfield {0-32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0be83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, dtype=str)->np.ndarray:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = []\n",
    "        line = f.readlines()\n",
    "        while line != '':\n",
    "            data.append(line)\n",
    "            line = f.readline()\n",
    "    return np.array(data, dtype=dtype).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "# loading WOS11967\n",
    "dataset_dir = './datasets/WOS11967/'\n",
    "\n",
    "input_file = dataset_dir + 'X.txt'\n",
    "X = load_data(input_file)\n",
    "    \n",
    "target_file = dataset_dir + 'Y.txt'\n",
    "Y = load_data(target_file, dtype=int)\n",
    "\n",
    "targetL1_file = dataset_dir + 'YL1.txt'\n",
    "YL1 = load_data(targetL1_file, dtype=int)\n",
    "\n",
    "targetL2_file = dataset_dir + 'YL2.txt'\n",
    "YL2 = load_data(targetL2_file, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d78c0e",
   "metadata": {},
   "source": [
    "Labels in YL1 (scientific field):\n",
    "\n",
    "- 0 - Computer Science\n",
    "- 1 - Electrical Engineering\n",
    "- 2 - Psychology\n",
    "- 3 - Mechanical Engineering\n",
    "- 4 - Civil Engineering\n",
    "- 5 - Medical Science\n",
    "- 6 - Biochemistry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878078d",
   "metadata": {},
   "source": [
    "# Implement LSTM class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15122a",
   "metadata": {},
   "source": [
    "- can use pytorch.nn.Module\n",
    "- For the LSTM model, you must design the data pre-processing pipeline that turns the unstructured text data into\n",
    "numerical features. You are free to choose your encoding method, including pre-trained methods like word2vec;\n",
    "however, there should be some justification for your choice in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def evaluate_acc(self, Y, Yhat):\n",
    "        return np.mean(Y == Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d4ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d55c16",
   "metadata": {},
   "source": [
    "# Implement BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba7db7",
   "metadata": {},
   "source": [
    "- For BERT, you can use the transformers package to tokenize the input text and convert the tokens into numeri-\n",
    "cal features https://pytorch.org/hub/huggingface_pytorch-transformers/\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp551",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
